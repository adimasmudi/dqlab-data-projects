{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp/ipykernel_6380/3708861958.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[feature] = LabelEncoder().fit_transform(df[feature])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "\n",
    "def concat_df(train_data, test_data):\n",
    "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n",
    "\n",
    "df_train = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/challenge/feature-engineering/titanic_train.csv')\n",
    "df_test = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/challenge/feature-engineering/titanic_test.csv')\n",
    "df_all = concat_df(df_train, df_test)\n",
    "df_train.name = 'Training Set'\n",
    "df_test.name = 'Test Set'\n",
    "df_all.name = 'All Set'\n",
    "\n",
    "age_by_pclass_sex = df_all.groupby(['Sex', 'Pclass']).median()['Age']\n",
    "df_all['Age'] = df_all.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "df_all['Embarked'] = df_all['Embarked'].fillna('S')\n",
    "med_fare = df_all.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\n",
    "df_all['Fare'] = df_all['Fare'].fillna(med_fare)\n",
    "df_all['Fare'] = pd.qcut(df_all['Fare'], 13)\n",
    "df_all['Family_Size'] = df_all['SibSp'] + df_all['Parch'] + 1\n",
    "\n",
    "family_map = {1: 'Alone', 2: 'Small', 3: 'Small', 4: 'Small', 5: 'Medium', 6: 'Medium', 7: 'Large', 8: 'Large', 11: 'Large'}\n",
    "df_all['Family_Size_Grouped'] = df_all['Family_Size'].map(family_map)\n",
    "df_all['Ticket_Frequency'] = df_all.groupby('Ticket')['Ticket'].transform('count')\n",
    "df_all['Title'] = df_all['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "df_all['Is_Married'] = 0\n",
    "df_all['Is_Married'].loc[df_all['Title'] == 'Mrs'] = 1\n",
    "df_all['Title'] = df_all['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms')\n",
    "df_all['Title'] = df_all['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy')\n",
    "\n",
    "\n",
    "df_train = df_all.loc[:890]\n",
    "df_test = df_all.loc[891:]\n",
    "dfs = [df_train, df_test]\n",
    "\n",
    "non_numeric_features = ['Embarked', 'Sex', 'Title', 'Family_Size_Grouped', 'Age', 'Fare']\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in non_numeric_features:        \n",
    "        df[feature] = LabelEncoder().fit_transform(df[feature])\n",
    "        \n",
    "cat_features = ['Pclass', 'Sex', 'Embarked', 'Title', 'Family_Size_Grouped']\n",
    "encoded_features = []\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in cat_features:\n",
    "        encoded_feat = OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()\n",
    "        n = df[feature].nunique()\n",
    "        cols = ['{}_{}'.format(feature, n) for n in range(1, n + 1)]\n",
    "        encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n",
    "        encoded_df.index = df.index\n",
    "        encoded_features.append(encoded_df)\n",
    "\n",
    "df_train = pd.concat([df_train, *encoded_features[:5]], axis=1)\n",
    "df_test = pd.concat([df_test, *encoded_features[5:]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perintah pertama bertujuan untuk membagi kembali dataset kita menjadi train dan test\n",
    "\n",
    "Perintah kedua adalah LabelEncoder untuk data‚Äù yang bersifat non-numeric, tujuannya adalah melakukan encoding [0-n] untuk data kategorikal. Contohnya Sex, akan dirubah menjadi 0 dan 1, laki-laki dan perempuan.\n",
    "\n",
    "Perintah ketiga bertujuan untuk mengubah feature kategori menjadi one hot, dengan OneHotEncoder. Akan menghasilkan beberapa kolom tergantung banyaknya kategori.\n",
    "\n",
    "Contohnya Pclass akan menjadi 3 kolom Pclass_1, Pclass_2, dan Pclass_3. Isinya adalah 0 dan 1 tergantung kategori orang tersebut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Embarked_1  Embarked_2  Embarked_3  Family_Size_Grouped_1  \\\n",
      "0   28         0.0         0.0         1.0                    0.0   \n",
      "1   52         1.0         0.0         0.0                    0.0   \n",
      "2   34         0.0         0.0         1.0                    1.0   \n",
      "3   48         0.0         0.0         1.0                    0.0   \n",
      "4   48         0.0         0.0         1.0                    1.0   \n",
      "\n",
      "   Family_Size_Grouped_2  Family_Size_Grouped_3  Family_Size_Grouped_4  Fare  \\\n",
      "0                    0.0                    0.0                    1.0     0   \n",
      "1                    0.0                    0.0                    1.0    11   \n",
      "2                    0.0                    0.0                    0.0     3   \n",
      "3                    0.0                    0.0                    1.0    10   \n",
      "4                    0.0                    0.0                    0.0     3   \n",
      "\n",
      "   Is_Married  ...  Pclass_2  Pclass_3  Sex_1  Sex_2  SibSp  Ticket_Frequency  \\\n",
      "0           0  ...       0.0       1.0    0.0    1.0      1                 1   \n",
      "1           1  ...       0.0       0.0    1.0    0.0      1                 2   \n",
      "2           0  ...       0.0       1.0    1.0    0.0      0                 1   \n",
      "3           1  ...       0.0       0.0    1.0    0.0      1                 2   \n",
      "4           0  ...       0.0       1.0    0.0    1.0      0                 1   \n",
      "\n",
      "   Title_1  Title_2  Title_3  Title_4  \n",
      "0      0.0      0.0      0.0      1.0  \n",
      "1      0.0      0.0      1.0      0.0  \n",
      "2      0.0      0.0      1.0      0.0  \n",
      "3      0.0      0.0      1.0      0.0  \n",
      "4      0.0      0.0      0.0      1.0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "df_all = concat_df(df_train, df_test)\n",
    "drop_cols = ['Cabin','Embarked','Family_Size','Family_Size_Grouped','Survived','Name','PassengerId','Pclass','Sex','Ticket','Title']\n",
    "\n",
    "df_all.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "print(df_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (891, 22)\n",
      "y_train shape: (891,)\n",
      "X_test shape: (418, 22)\n"
     ]
    }
   ],
   "source": [
    "X_train = StandardScaler().fit_transform(df_train.drop(columns=drop_cols))\n",
    "y_train = df_train['Survived'].values\n",
    "X_test = StandardScaler().fit_transform(df_test.drop(columns=drop_cols))\n",
    "\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6380/4240200669.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m random_forest = RandomForestClassifier(criterion='gini', \n\u001b[0m\u001b[0;32m      2\u001b[0m                                            \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                            \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                            \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                            \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(criterion='gini', \n",
    "                                           n_estimators=1100,\n",
    "                                           max_depth=5,\n",
    "                                           min_samples_split=4,\n",
    "                                           min_samples_leaf=5,\n",
    "                                           max_features='auto',\n",
    "                                           oob_score=True,\n",
    "                                           random_state=50)\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# konklusi\n",
    "Feature Engineering mengharuskan kita membuat banyak ide fitur dari data yang sudah ada.\n",
    "\n",
    "Biasanya yang dapat kita lakukan adalah, penggabungan (grouping), ekstraksi fitur (seperti Title yang didapat dari nama orang), dan masih banyak lagi.\n",
    "\n",
    "Jangan malas untuk melakukan feature engineering dan mencoba segala sesuatu yang ada di pikiran kita. Barangkali ini dapat meningkatkan akurasi model kita."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50c5c2b6e05db9fe8b3433ad8e6dc52eedfaade324407e06c6799762d580ed33"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
